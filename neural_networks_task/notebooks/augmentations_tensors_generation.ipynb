{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchaudio\n",
    "from torchaudio.transforms import MelSpectrogram, Resample\n",
    "from skimage.util import random_noise\n",
    "\n",
    "\n",
    "CONFIG = {\n",
    "    \"epochs\": 30,\n",
    "    \"num_classes\": 264,\n",
    "    \"train_batch_size\": 16,\n",
    "    \"eval_batch_size\": 16,\n",
    "    \"eval_split_ratio\": 0.2,\n",
    "    \"stratify_column\": \"primary_label\",\n",
    "    \"sample_rate\": 32_000,\n",
    "    \"hop_length\": 512,\n",
    "    \"max_time\": 5,\n",
    "    \"n_mels\": 224,\n",
    "    \"n_fft\": 1024,\n",
    "    \"learning_rate\": 1e-5,\n",
    "    \"PLOTS_DIR\": \"./plots/results\",\n",
    "    \"RESULTS_DIR\": \"./results\",\n",
    "    \"MODELS_DIR\": \"./saved_models\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_mono(audio):\n",
    "    return torch.mean(audio, axis=0)\n",
    "\n",
    "\n",
    "def crop_audio(audio, num_samples):\n",
    "    return audio[:num_samples]\n",
    "\n",
    "\n",
    "def pad_audio(audio, num_samples):\n",
    "    pad_length = num_samples - audio.shape[0]\n",
    "    last_dim_padding = (0, pad_length)\n",
    "    audio = F.pad(audio, last_dim_padding)\n",
    "    return audio\n",
    "\n",
    "\n",
    "def generate_spectrogram(filepath, target_sample_rate, num_samples):\n",
    "    audio, sample_rate = torchaudio.load(filepath, format=\"ogg\")\n",
    "    audio = to_mono(audio)\n",
    "\n",
    "    if sample_rate != target_sample_rate:\n",
    "        resample = Resample(sample_rate, target_sample_rate)\n",
    "        audio = resample(audio)\n",
    "\n",
    "    if audio.shape[0] > num_samples:\n",
    "        audio = crop_audio(audio, num_samples)\n",
    "\n",
    "    if audio.shape[0] < num_samples:\n",
    "        audio = pad_audio(audio, num_samples)\n",
    "\n",
    "    mel_spectrogram = MelSpectrogram(\n",
    "        sample_rate=target_sample_rate, n_mels=CONFIG[\"n_mels\"], n_fft=CONFIG[\"n_fft\"]\n",
    "    )\n",
    "    mel = mel_spectrogram(audio)\n",
    "    return mel\n",
    "\n",
    "\n",
    "def save_mel_tensor(mel_tensor, output_filename):\n",
    "    torch.save(mel_tensor, output_filename)\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"../data/train_metadata.csv\")\n",
    "\n",
    "output_dir = \"../data/tensors/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    print(f\"Row {index} / {len(data)}\")\n",
    "    audio_filepath = \"../data/train_audio/\" + row[\"filename\"]\n",
    "    os.makedirs(output_dir + row[\"filename\"].split(\"/\")[0], exist_ok=True)\n",
    "    output_filename = os.path.join(output_dir, os.path.splitext(row[\"filename\"])[0] + \".pt\")\n",
    "    mel = generate_spectrogram(audio_filepath, CONFIG[\"sample_rate\"], CONFIG[\"sample_rate\"] * 5)\n",
    "    save_mel_tensor(mel, output_filename)\n",
    "\n",
    "print(\"Spectrogram generation and saving complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian_noise_to_mel(mel_tensor, mean=0, var=0.05):\n",
    "    mel_np = mel_tensor.numpy()\n",
    "    noisy_mel_np = random_noise(mel_np, mode=\"gaussian\", mean=mean, var=var, clip=True)\n",
    "    noisy_mel_tensor = torch.tensor(noisy_mel_np, dtype=mel_tensor.dtype)\n",
    "\n",
    "    return noisy_mel_tensor\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"../data/train_metadata.csv\")\n",
    "least_common_names = data[\"common_name\"].value_counts().nsmallest(100).index\n",
    "filtered_data = data[data[\"common_name\"].isin(least_common_names)]\n",
    "filtered_data.reset_index(drop=True, inplace=True)\n",
    "augmented_entries = []\n",
    "\n",
    "for index, row in filtered_data.iterrows():\n",
    "    print(f\"Row {index} of {len(filtered_data)}\")\n",
    "    audio_filepath = \"../data/train_audio/\" + row[\"filename\"]\n",
    "    mel = generate_spectrogram(audio_filepath, CONFIG[\"sample_rate\"], CONFIG[\"sample_rate\"] * 5)\n",
    "\n",
    "    noisy_mel = add_gaussian_noise_to_mel(mel)\n",
    "\n",
    "    augmented_filename = os.path.splitext(row[\"filename\"])[0] + \"_augmented.pt\"\n",
    "    output_filename = os.path.join(output_dir, augmented_filename)\n",
    "\n",
    "    save_mel_tensor(noisy_mel, output_filename)\n",
    "\n",
    "    new_row = row.copy()\n",
    "    new_row[\"filename\"] = augmented_filename\n",
    "    augmented_entries.append(new_row)\n",
    "\n",
    "augmented_data = pd.DataFrame(augmented_entries)\n",
    "data_with_augmentations = pd.concat([data, augmented_data], ignore_index=True)\n",
    "data_with_augmentations.to_csv(\"../data/train_metadata_with_augmentations.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"filename_tensor\"] = [path.split(\".\")[0] + \".pt\" for path in data[\"filename\"]]\n",
    "data_with_augmentations[\"filename_tensor\"] = [path.split(\".\")[0] + \".pt\" for path in data_with_augmentations[\"filename\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_augmentations.to_csv(\"../data/train_metadata_with_augmentations.csv\", index=False)\n",
    "data.to_csv(\"../data/train_metadata.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
